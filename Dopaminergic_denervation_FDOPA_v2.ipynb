{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dopaminergic denervation FDOPA v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirolab/FDOPA-PET-analysis/blob/main/Dopaminergic_denervation_FDOPA_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wR1wZ4FXt3B"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "import tqdm\n",
        "from scipy import stats\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sk\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegressionCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS8CwC0qK-iT"
      },
      "source": [
        "# Models 1, 2, 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w82TeFwoYzk_"
      },
      "source": [
        "# Importing data and defining the feature list\n",
        "data =\n",
        "label =\n",
        "\n",
        "INFO_patient = [x for x in list(data.columns) if x.split('_')[0]=='INFO']\n",
        "\n",
        "FEATURES = \n",
        "LABEL = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjJnziAIY3E5"
      },
      "source": [
        "# Data cleanup\n",
        "striatum_D = data.drop_duplicates(subset='INFO_PatientID', keep=\"first\").reset_index()[FEATURES]\n",
        "striatum_G = data.drop_duplicates(subset='INFO_PatientID', keep=\"last\").reset_index()[FEATURES]\n",
        "radiomics_features = striatum_D + striatum_G\n",
        "radiomics_features = radiomics_features/2\n",
        "patients_info = data.drop_duplicates(subset='INFO_PatientID', keep=\"first\").reset_index()[INFO_patient]\n",
        "datawithlabel = pd.concat((radiomics_features, label), axis=1)\n",
        "patients_info = patients_info[patients_info.INFO_ActualFrameDuration=='6.0 min']\n",
        "datawithlabel = datawithlabel.loc[patients_info.index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3V6R8sanyz4"
      },
      "source": [
        "# Model code (replacing the feature list as appropriate)\n",
        "scores = []\n",
        "coeffs = []\n",
        "for repet in tqdm.tqdm(range(1000)):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(datawithlabel[FEATURES], datawithlabel[LABEL].values.flatten(), test_size=0.25)\n",
        "  scaler = StandardScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "  cv = LogisticRegressionCV(cv = 5, penalty = 'l1', solver = 'saga', scoring='roc_auc', Cs = np.logspace(-1,1,20), max_iter=10000)\n",
        "  cv.fit(X_train, y_train)\n",
        "  scores.append(cv.score(X_test, y_test)*100)\n",
        "  coeffs.append(list(cv.coef_.T.flatten()))\n",
        "print(np.mean(scores), np.std(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWCponCmFIaN"
      },
      "source": [
        "# List of scores\n",
        "scores.sort()\n",
        "scores_df = DataFrame(scores,columns=['Score'])\n",
        "scores_df.to_excel(\"bootstrap scores.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0G2eaxhceeF"
      },
      "source": [
        "# List of features\n",
        "proba_df = pd.DataFrame(data = (abs(np.array(coeffs))>0).sum(0)/len(coeffs), index=FEATURES, columns=['proba'])\n",
        "scores_df = pd.DataFrame(data = np.array(coeffs).sum(0)/(np.array(coeffs)!=0).sum(0), index=FEATURES, columns=['score'])\n",
        "scores_df = scores_df.fillna(0)\n",
        "dataframe = pd.concat([proba_df,scores_df],1).sort_values('proba', ascending=False)\n",
        "dataframe.to_excel(\"feature list.xlsx\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC8IXqjyOW25"
      },
      "source": [
        "# External validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58euzxgAOjVq"
      },
      "source": [
        "data_val = \n",
        "label_val =\n",
        "FINAL_FEATURES = \n",
        "# Training\n",
        "X_train, y_train = datawithlabel[FINAL_FEATURES], datawithlabel[LABEL].values.flatten()\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "logreg = LogisticRegression(penalty = 'none')\n",
        "logreg.fit(X_train, y_train)\n",
        "# Testing\n",
        "auroc = logreg.score(scaler.transform(data_val[FINAL_FEATURES]), label_val.values.flatten())*100\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(label_val.values.flatten(), logreg.predict(scaler.transform(data_val[FINAL_FEATURES]))).ravel()\n",
        "sensitivity = tp / (tp+fn) * 100\n",
        "specificity = tn / (tn+fp) * 100\n",
        "accuracy = (tp+tn)/(tp+tn+fp+fn) * 100\n",
        "\n",
        "print(\"AUROC: {} \\t Acc: {} \\t Sensitivity: {} \\t Specificity : {}\".format(auroc, accuracy, sensitivity, specificity))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J472DtBQMuHZ"
      },
      "source": [
        "# Model for clinical scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soVSPPjVMvx7"
      },
      "source": [
        "scores = \n",
        "score_label = \n",
        "mean_imputation = scores.fillna(scores.median())\n",
        "scores = []\n",
        "coeffs = []\n",
        "for repet in tqdm.tqdm(range(1000)):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(mean_imputation, score_label.values.flatten(), test_size=0.25)\n",
        "  scaler = StandardScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "  cv = LogisticRegressionCV(cv = 5, penalty = 'l1', solver = 'saga', scoring='roc_auc', Cs = np.logspace(-1,1,20), max_iter=10000)\n",
        "  cv.fit(X_train, y_train)\n",
        "  scores.append(cv.score(X_test, y_test)*100)\n",
        "  coeffs.append(list(cv.coef_.T.flatten()))\n",
        "print(np.mean(scores), np.std(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7QPi7rFLBD_"
      },
      "source": [
        "# CCC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbf5GHEbLEhZ"
      },
      "source": [
        "# CCC code from https://github.com/stylianos-kampakis/supervisedPCA-Python/blob/master/Untitled.py\n",
        "def concordance_correlation_coefficient(y_true, y_pred,\n",
        "                       sample_weight=None,\n",
        "                       multioutput='uniform_average'):\n",
        "    cor=np.corrcoef(y_true,y_pred)[0][1]\n",
        "    mean_true=np.mean(y_true)\n",
        "    mean_pred=np.mean(y_pred)\n",
        "    var_true=np.var(y_true)\n",
        "    var_pred=np.var(y_pred)\n",
        "    sd_true=np.std(y_true)\n",
        "    sd_pred=np.std(y_pred)\n",
        "    numerator=2*cor*sd_true*sd_pred\n",
        "    denominator=var_true+var_pred+(mean_true-mean_pred)**2\n",
        "    return numerator/denominator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF4YxClbL9e5"
      },
      "source": [
        "# Pearson correlogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh0diu4aL-rn"
      },
      "source": [
        "path =\n",
        "listfile = os.listdir(path)\n",
        "list_corr = []\n",
        "for name_file in listfile:\n",
        "  data = pd.read_excel(path+name_file, header=0)\n",
        "  striatum_D = data.drop_duplicates(subset='INFO_PatientID', keep=\"first\").reset_index()[usefuldata]\n",
        "  striatum_G = data.drop_duplicates(subset='INFO_PatientID', keep=\"last\").reset_index()[usefuldata]\n",
        "  radiomics_features = striatum_D + striatum_G\n",
        "  radiomics_features.drop(RIM, axis=1, inplace=True)\n",
        "  radiomics_features = radiomics_features/2\n",
        "  X = radiomics_features[FEATURES]\n",
        "  X.rename(columns={\"CONVENTIONAL_TLG(mL)(onlyForPETorNM)\": \"CONVENTIONAL_TLG(mL)\",\n",
        "                    'SHAPE_Sphericity(onlyFor3DROI))':'SHAPE_Sphericity',\n",
        "                    'SHAPE_Surface(mm2)(onlyFor3DROI)':'SHAPE_Surface(mm2)',\n",
        "                    'SHAPE_Compacity(onlyFor3DROI)':'SHAPE_Compacity'}, inplace=True)\n",
        "  list_corr.append(X.corr('pearson'))\n",
        "ax = sns.clustermap(sum(list_corr)/len(list_corr))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}